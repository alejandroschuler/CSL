---
interact_link: content/what-is-sl.ipynb
kernel_name: python3
kernel_path: content
has_widgets: false
title: |-
  What is Supervised Learning?
pagenum: 3
prev_page:
  url: /questions.html
next_page:
  url: /grad-descent/grad-descent.html
suffix: .ipynb
search: x learning y supervised blood pressure model our data predict patients treatment well patient observation array given called n based also predictors questions example machine p measurements pre refer problem book used input photographs spam not often better etc measurement left begin cdots end right its vdots prediction might answer output either cats new predicting weather future e g includes already discuss position understand ideas formalize heart rate post subscript ith value unit numbers target features j xi vector lists prevbloodpressure rule trying previously algorithm label matter tomorrows temperature todays diabetic non emails tool however same sometimes statistical assumptions useful

comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---

    <main class="jupyter-page">
    <div id="page-info"><div id="page-title">What is Supervised Learning?</div>
</div>
    
<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we know what kinds of questions we might be trying to answer, but since this book is about <em>supervised learning</em>, we should now define what that is and how it can be used to answer the questions we have.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Supervised learning is the task of figuring out how to guess the output from a given input based on previously seen pairings of output and input. For example, given 1000 photographs labeled as either pictures of cats or dogs, can we build an algorithm to assign the label "cat" or "dog" to new photographs of unknown subject matter?</p>
<p>Here are some more examples of problems we could use supervised learning for:</p>
<ul>
<li>predicting tomorrow's temperature given today's weather, based on prior weather data</li>
<li>predicting which future patients will develop diabetes, based on data on past diabetic and non-diabetic patients</li>
<li>labeling emails as either spam or not spam based on a database of spam and non-spam emails</li>
</ul>
<p>Supervised learning, therefore, is the perfect tool to use for <em>predictive</em> questions. However, as we saw in our regression example, the same tool can sometimes be used for multiple purposes. All supervised learning algorithms can, with some additional statistical assumptions and machinery, be useful in answering causal questions or doing inference. Supervised learning is also a starting point for learning about <em>reinforcement and policy learning</em>, which are also causal in nature. That's because some part of all of these tasks involves estimating how an input (e.g. today's weather) produces an output (e.g. tomorrow's temperature).</p>
<p>Supervised learning is one kind of method out of the grab-bag of techniques that are collectively called <em>machine learning</em>. Machine learning also includes <em>unsupervised learning</em>, which are methods that discover the most obvious groupings or patterns in the data. Unsupervised learning is most often useful in exploratory analyses. Machine learning also includes reinforcement learning, which we have already touched upon, and which often uses tools from supervised learning. This book won't further discuss either of these topics, but I think you will be in a better position to understand them once you've understood supervised learning as a point of reference.</p>
<p>Machine learning does not include fundamental statistical concepts like p-values and confidence intervals. These ideas help us understand when an association is unlikely to have arisen from random chance, given some assumptions. They do not concern themselves with predicting an outcome from an input. However, these ideas can certainly be used in conjunction with machine learning to answer inferential questions, as previously alluded to. We won't discuss these ideas in this book, but, again, I think you'll be in a better position to understand them if you clearly distinguish them from supervised learning.</p>
<p>All that said, we are finally in a position to formalize what we mean by "supervised learning".</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Data-for-Supervised-Learning">Data for Supervised Learning<a class="anchor-link" href="#Data-for-Supervised-Learning"> </a></h2><p>The first step is to formalize the kind of data we expect to use for supervised learning.</p>
<p>Pretend we observe 1000 patients in a hospital, each of whom has measurements of their pre-treatment blood pressure, heart rate, etc. and also their corresponding blood pressure after taking a drug. We'll call this our <em>training data</em>. For a new patient who walks in the door, given their current vital signs, can we predict their post-treatment blood pressure?</p>
<p>We'll use a subscript $i$ to refer to data about the $i$th patient. So, for example, if $z$ were some measurement we made on all patients, $z_i$ would be the value of that measurement for the $i$th patient. The patient in our example is what we call the <strong>unit of observation</strong>. But if we were talking about classifying photographs as having cats or not having cats in them, the unit of observation would be the photographs. So, in general, the subscript $i$ refers to the $i$th observation in the dataset, which could be a patient, a photograph, a credit card transaction, etc.</p>
<p>The total number of observations in our data is usually called $n$, so $i$ could stand for any number between 1 and $n$. A shorter way to write that is $i \in \{1, 2, \dots n\}$. You can read $\in$ as "in", so this says "$i$ is a number in the set of numbers that includes 1, 2, ... all the way up to $n$". We'll use that notation for other things as well.</p>
<p>We usually use the variable $y$ to refer to the measurement we are trying to predict, which is in this case the patient's post-treatment blood pressure. You'll most often see $y$ called the <strong>target</strong>, <strong>label</strong>, or <strong>outcome</strong>. Using our observation subscripts, $y_1$ would be the first patient's post-treatment blood pressure, $y_2$ would be the second patient's blood pressure, etc.</p>
<p>We can do the same thing for the other measurements, which are called <strong>predictors</strong>, <strong>features</strong>, or <strong>covariates</strong>. We could use different letters for each predictor, e.g. pre-treatment blood pressure would be $z$, pre-treatment heart rate would be $x$, but the standard practice is to call them all "$x$", but subscript them with an index $j$ (different than the index $i$ that refers to the unit of observation). So, in our example, we'll say $x_{i1}$ is patient $i$'s pre-treatment blood pressure, $x_{i2}$ is their pre-treatment heart rate, etc. We will use $p$ to refer to the number of predictors we have for each observation, so $j \in \{1 \dots p\}$. We'll use $x_i$ to refer to a list of all of the features for observation $i$:</p>
$$
x_i = 
\left[
\begin{array}{cccc}
x_{i1} &amp; x_{i2} &amp; \cdots &amp; x_{ip}
\end{array}
\right] 
$$<p>Now each observation is decribed by its target $y_i$ and its vector of predictors $x_i$. We stack these measurements together into lists of outcomes and predictors so we can refer to all of them at once:</p>
$$
X = 
\left[
\begin{array}{c}
x_1 \\ x_2 \\ \vdots \\ x_n
\end{array}
\right] 
=
\left[
\begin{array}{cccc}
x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1p} \\
x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2p} \\
\vdots &amp; &amp; \ddots &amp; \vdots \\
x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{np} 
\end{array}
\right]
\quad
Y = 
\left[
\begin{array}{c}
y_1 \\ y_2 \\ \vdots \\ y_n
\end{array}
\right] 
$$<p>You may recall that ordered lists of numbers are also called vectors, and a list of lists of numbers (like $X$) can be written as a matrix. These are the terms we'll use going forward.</p>
<p>Note that each column of $X$ (which we'll call $x_{:j}$) is a vector that contains every measurement of the $j$th feature.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell tag_hide_input">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Exercise with a supervised learning example- what are the xs and ys, unit of obs, etc.</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell tag_hide_input">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># example in a pandas dataframe, etc.</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Learning">Learning<a class="anchor-link" href="#Learning"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we can formalize our learning problem in the abstract. All the measurements for the existing patients are contained in the matrix of predictors $X$ and the vector of targets $Y$. A new patient walks in the door (patient #$n+1$), and we measure all their predictors $x$. What we don't observe, but want to estimate, is the value of their target, $y$.</p>
<p>One way to approach this problem is to solve it manually. For instance, we could write up a program based on our knowledge of how blood pressure changes in response to drugs to make a prediction. It might look something like this:</p>

<pre><code>def predict(x)
    prev_blood_pressure, age, ... = x

    if age &lt; 16:
        y = 120
    if prev_blood_pressure &gt; 150:
        y = 1.1*prev_blood_pressure
    ...

    return y</code></pre>
<p>The problem with this is that it assumes we already know how to predict future blood pressure given what we know. But what if we have no idea how the features can be used to predict future blood pressure? Or what if we have a vague idea, but don't know if our prediction is really the best that we could hope for? What would be ideal is if a computer could analyze the data we already have and then write the <code>predict()</code> code for us. That is precisely what we are going to learn about in this book.</p>
<p>The process of building a <em>model</em> that can produce estimates of $y$ given $x$ based on the measurements in the training data $X$ and $Y$ is often called <em>fitting</em> or <em>learning</em> the model. What you get out of that process is a rule, or an algorithm, that associates a value $y$ for each possible $x$ you feed to it (basically, the <code>predict()</code> function). That rule is sometimes called the <em>fit model</em> or the <em>prediction rule</em>.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell tag_hide_input">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># example with sklearn:</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">

<pre><code>X, Y = load_and_process_data()
model = learn(X,Y)
y_predicted = model.predict(x_new)</code></pre>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Evaluating">Evaluating<a class="anchor-link" href="#Evaluating"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>But that's only half of the challenge. It's actually pretty easy to come up with <em>a</em> model. For instance, a dumb model for the blood pressure prediction problem might be to always predict $y=120$, no matter what $x$ is.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">

<pre><code>def predict(x):
    return 120</code></pre>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>But how do we know that this model is better or worse than another model? How do we know our fancy deep neural network can outperform a trained monkey? And what exactly do we mean by "better" anyways? That is the problem of <em>evaluating</em> our model, and it is actually more subtle than you'd expect. We will discuss model evaluation and its cousin, <em>model selection</em> after we've learned how to fit models.</p>

</div>
</div>
</div>
</div>

 


    </main>
    