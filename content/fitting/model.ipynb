{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A *model* is anything that people make to mimic some facet of reality. The purpose of models is to be able to answer questions about reality without having to interrogate the real world (e.g. run experiments). For instance, let's say we want to know how long it will take a ball to roll down a hill. Instead of going out that hill with a ball, which could take time and effort, we could use a model to answer our question instead. \n",
    "\n",
    "In this case, we might use a model based on Newton's laws of motion. But no matter what model we use, we are only approximating what would happen in the real world. For instance, to time our ball rolling, we might ignore the effects of air resistance, the elasticity and deformation of the ball, the imperfections in the surface of the hill, the tidal force of the moon, etc. No matter how detailed or accurate, models are always simplifications. Some of our models (e.g. Newtonian physics) are so good that we sometimes think that they *are* reality. But that's not the case. Newtonian physics was superceded by quantum mechanics and general relativity, which themselves will be superceded one day. As the saying goes, no model is perfect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "popout"
    ]
   },
   "source": [
    "Supervised learning models are not necessarily useful for determining *why* an outcome is likely or what we could do to change an outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But many are useful; depending on what they are used for. For instance, a toy car is a useful model for teaching someone to recognize a real car, but useless for estimating how much a real car weighs, or for explaining an internal combustion engine. In supervised learning, we want to build models that are useful for predicting an outcome from predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "popout"
    ]
   },
   "source": [
    "We'll use the \"hat\" notation $\\hat y$ to denote a value that is an estimate of another value (in this case $y$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically, the supervised learning problem is to assign a most likely output to every combination of possible inputs. Consequently, models in supervised learning are represented by mathematical functions, like $f(x) = x^2$, which are mappings from an input to an output. So, if $f(x) = x^2$ and we pass the input (predictors) $x=2$, the output (estimated outcome) will be $\\hat y = f(2) = 2^2 = 4$. In other words, the function $f$ is the \"code\" that we use to predict $y$, e.g:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x):\n",
    "    return x**2\n",
    "\n",
    "f(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturally, functions can also take more than one variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x0, x1):\n",
    "    return x0**2 + x1\n",
    "\n",
    "f(2,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, equivalently, a vector of variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x):\n",
    "    return x[0]**2 + x[1]\n",
    "\n",
    "f([2,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our task, then, is to use the data $X,Y$ to come up with a function so that for new $x$ and $y$, $y \\approx f(x)$. That will be our model of the world. So a supervised learning method is really an algorithm that takes data and returns a function.\n",
    "\n",
    "But is there a \"real\" $f$ that generates $y$ from $x$ in the physical world? Not necessarily. In fact, the \"outcome\" might not even precede the \"predictors\". For example, consider a model that looks at photographs ($x$) to determine if there is a cat or a dog ($y$) in the image. We're pretending there's a function that associates a label of cat or dog to every image, whereas, in reality, the subject of the photograph was a cat or a dog before the picture was taken. The predictors of the label (i.e. the pixels in the image) were in fact consequences of the label, not the other way around. Furthermore, in the real world, the same predictors can reoccur with a different outcome. For instance, if we try to predict college graduates' incomes based on their majors alone, we are likely to find two students in our data with the same major but with different incomes (because other factors besides major also contribute to income). Our predictive model, however, is a function, so the same input will always produce the same output and these two students will be predicted to have the same outcome. That's not a problem- the model will still produce our best guess based on major alone, but clearly the real-world data are not generated by a deterministic function. So be careful about imagining that there is some \"real\" function that we are trying to estimate. It's better to imagine instead that there is a \"most accurate model\" that we are trying to get close to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
